{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Using KNieghbors, DecisionTree, and Random Forest to predict a U Prep student's happiness, stress, and energy level at any given time. \n",
    "\n",
    "<h4> by Tessa de Vries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro: For my preliminary round of classifying I used the following 6 features for each level I was trying to predict. Day of the week, # of graded assessements today, hours slept last night, # of times exercised in the last 7 days (20+ min), and the two levels that I was not trying to predict.  These were selected because in my personal experience they are the factors that are most influential in the output levels. \n",
    "\n",
    "<h3> ACCURACY: Predicting Stress Level (6 features- DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115384615385\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "raw_data = open(\"stress.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "X = dataset[:,0:6]\n",
    "y = dataset[:,6]\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20)\n",
    "\n",
    "from sklearn import tree\n",
    "tree_classifier = tree.DecisionTreeClassifier();\n",
    "tree_classifier = tree_classifier.fit(X_train, y_train)\n",
    "tree_predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(tree_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Stresst Level (6 features- KNeighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051724137931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn_classifier = neighbors.KNeighborsClassifier()\n",
    "knn_classifier = knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(knn_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Stresst Level (6 features- RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0172413793103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Happiness Level (6 features-DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "raw_data = open(\"happy1.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "X = dataset[:,0:6]\n",
    "y = dataset[:,6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.275862068966\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import tree\n",
    "tree_classifier = tree.DecisionTreeClassifier();\n",
    "tree_classifier = tree_classifier.fit(X_train, y_train)\n",
    "tree_predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(tree_predictions, y_test))\n",
    "       \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Happiness (6 features-KNieghbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.128205128205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20)\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn_classifier = neighbors.KNeighborsClassifier()\n",
    "knn_classifier = knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(knn_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Happiness (6 features- RandomForest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.230769230769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20)\n",
    "\n",
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Energy Level (6 features- DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.120689655172\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "raw_data = open(\"energy.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "X = dataset[:,0:6]\n",
    "y = dataset[:,6]\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import tree\n",
    "tree_classifier = tree.DecisionTreeClassifier();\n",
    "tree_classifier = tree_classifier.fit(X_train, y_train)\n",
    "tree_predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(tree_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Happiness( 6 features- KNieghbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.172413793103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn_classifier = neighbors.KNeighborsClassifier()\n",
    "knn_classifier = knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(knn_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Happiness (6 fetaures- RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.172413793103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis: Due to the fact that my accuracies were fairly low across the board, I decided to do further analysis. Initially I did this through using regression (I uploaded the file with this code--it's name is \"Final (regressions)\") but that did not provide any better results. I was not able to find any strong correlations between any single feature and my intended target level (happiness, stress, or energy). I decided to go back to machine learning, specifically the three techniques I used previously (Decision Tree, KNieghbors, and RandomForest). I thought that reducing the features from 6 to 3 for each level would produce higher accuracy levels. I also selected features that I thought were the most influential in determining the outputs. The features for Happiness were : day of the week, hours of sleep last night, and stress level. The features for Energy were: happiness level, # of graded assessements today, and hours of sleep last night. The features for Stress were: # of graded assessements today, # of times exercised in the last 7 days (20+ min), and hours of sleep last night. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3> ACCURACY: Predicting Stress Level(3 features- DecisionTree, KNieghbors, RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.166666666667\n",
      "0.120689655172\n",
      "0.103448275862\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "raw_data = open(\"stress1.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "X = dataset[:,0:3]\n",
    "y = dataset[:,3]\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20)\n",
    "\n",
    "from sklearn import tree\n",
    "tree_classifier = tree.DecisionTreeClassifier();\n",
    "tree_classifier = tree_classifier.fit(X_train, y_train)\n",
    "tree_predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(tree_predictions, y_test))\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn_classifier = neighbors.KNeighborsClassifier()\n",
    "knn_classifier = knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(knn_predictions, y_test))\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Energy Level(3 features- DecisionTree, KNieghbors, RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.166666666667\n",
      "0.155172413793\n",
      "0.137931034483\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "raw_data = open(\"energy1.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "X = dataset[:,0:3]\n",
    "y = dataset[:,3]\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20)\n",
    "\n",
    "from sklearn import tree\n",
    "tree_classifier = tree.DecisionTreeClassifier();\n",
    "tree_classifier = tree_classifier.fit(X_train, y_train)\n",
    "tree_predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(tree_predictions, y_test))\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn_classifier = neighbors.KNeighborsClassifier()\n",
    "knn_classifier = knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(knn_predictions, y_test))\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ACCURACY: Predicting Happiness Level(3 features- DecisionTree, KNieghbors, RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.153846153846\n",
      "0.137931034483\n",
      "0.224137931034\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "raw_data = open(\"happy2.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "X = dataset[:,0:3]\n",
    "y = dataset[:,3]\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20)\n",
    "\n",
    "from sklearn import tree\n",
    "tree_classifier = tree.DecisionTreeClassifier();\n",
    "tree_classifier = tree_classifier.fit(X_train, y_train)\n",
    "tree_predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(tree_predictions, y_test))\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn_classifier = neighbors.KNeighborsClassifier()\n",
    "knn_classifier = knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(knn_predictions, y_test))\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Unfortunately my accuracies were not exceptionally higher or even close to what I wanted (around 80%). However, the accuracy for stress almost doubled from 6 to 13%! And the accuracy for energy increased significantly as well. Happiness on the other hand decreased about 4%. \n",
    "\n",
    "After doing this analysis I realize how personal and arbitrary \"happiness, stress, and energy\" levels are. One person's 7 may be another person's 3 (so to speak). This also makes me question how thoroughly and thoughtfully people fill out surveys. Perhaps the reason my accuracy levels were so low was because the data wasn't accurate do to peoples' inaccuracy in the survey. I have a feeling that people may have started to do the survey rushed considering it was for a Stats Class and required every week for several weeks. \n",
    "\n",
    "I would have enjoyed being able to code a model with a very high accuracy but I realize that you don't always get the results you initally desire. Furthermore, just because I didn't get very functional product not only doesn't mean I didn't put a lot of work into the lab but it also doesn't mean I didn't learn anything from the low accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
